{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from tensorflow import nn\n",
    "from numpy import zeros\n",
    "from numpy.random import randint\n",
    "import tensorflow.keras as keras\n",
    "from keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras import layers, regularizers\n",
    "# end imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurations : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# Params\n",
    "#############\n",
    "\n",
    "# DATA\n",
    "PLANES = 31\n",
    "MOVES = 361\n",
    "N = 10_000\n",
    "DIM = 19\n",
    "\n",
    "# MODEL\n",
    "FILTERS = 64\n",
    "KERNEL_SIZE = (3,3)\n",
    "\n",
    "# TRAIN\n",
    "NB_EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Shape Data (In/Out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    -------------------------------------------------------------------------------------------     \n",
    "        DataHandler : in this class we handle all stuff related to data shaping and/or\n",
    "                    data to tensors creations this returned data will be helpful for training\n",
    "                    and exploited by golois.cpp util function as (getBatch and getValidation).\n",
    "    -------------------------------------------------------------------------------------------\n",
    "'''\n",
    "class DataHandler(object):\n",
    "    \n",
    "    def __init__(self,n_samples=N,dim=DIM,n_moves=MOVES,n_planes=PLANES) -> None:\n",
    "        super().__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.dim = dim\n",
    "        self.n_moves = n_moves\n",
    "        self.n_planes = n_planes\n",
    "    \n",
    "    def get_data(self):\n",
    "        # Inputs\n",
    "        input_data = randint(2, size=(self.n_samples, self.dim, self.dim, self.n_planes)).astype ('float32')\n",
    "\n",
    "        # Outputs \n",
    "        policy = to_categorical(randint(self.n_moves, size=(self.n_samples,)))\n",
    "        value =  randint(2, size=(self.n_samples,)).astype ('float32')\n",
    "\n",
    "        # For Get_Batch & Get_Validation\n",
    "        end = randint(2, size=(self.n_samples, self.dim, self.dim, 2)).astype ('float32')\n",
    "        groups = zeros((self.n_samples, self.dim, self.dim, 1)).astype ('float32')\n",
    "\n",
    "        return input_data , policy , value , end , groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- DeepGO Model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    -------------------------------------------------------------------------------------------     \n",
    "        DGM (DeepGoModel) : in this class we handle all stuff related to the deep neural model\n",
    "                            who will represent our GO player all versions with different \n",
    "                            architechtures will inheritat this basic methods and added to them\n",
    "                            their new specific blocks or methods.\n",
    "    -------------------------------------------------------------------------------------------\n",
    "'''\n",
    "class DGM(object):\n",
    "    \n",
    "    def __init__(self,version=0,dim=DIM,n_moves=MOVES,n_planes=PLANES,n_filters=FILTERS,\n",
    "                kernel_size=KERNEL_SIZE,l2_reg=0.0001,dropout=0.2,n_res_blocks=6) -> None:\n",
    "        super().__init__()\n",
    "        self.version = version\n",
    "        self.dim = dim\n",
    "        self.n_moves = n_moves\n",
    "        self.n_planes = n_planes\n",
    "        self.n_filters = n_filters\n",
    "        self.kernel = kernel_size\n",
    "        self.l2_reg = regularizers.l2(l2_reg)\n",
    "        self.dropout = dropout\n",
    "        self.n_res_blocks = n_res_blocks\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f'DGMV{self.version}'\n",
    "\n",
    "    def plot_model(self,save_path='model_imgs'):\n",
    "        \n",
    "        if not self.model:\n",
    "            print(f' You should build the model first !')\n",
    "            return\n",
    "        to_file = os.path.join(os.getcwd,save_path,f'{str(self)}.png')\n",
    "\n",
    "        plot_model(self.model,to_file=to_file,show_shapes=True)\n",
    "        \n",
    "    def build_model(self):\n",
    "        # Input Block\n",
    "        inp = keras.Input(shape=(self.dim, self.dim, self.n_planes), name='board')\n",
    "        x = self.input_block(inp)\n",
    "\n",
    "        # Residual Blocks \n",
    "        for _ in range(self.n_res_blocks):\n",
    "            x = self.residual_block(x)\n",
    "\n",
    "        # Outputs blocks\n",
    "        policy_head = self.output_policy_block(x)\n",
    "        value_head = self.output_value_block(x)\n",
    "\n",
    "        # Build model \n",
    "        self.model = keras.Model(inputs=inp, outputs=[policy_head, value_head])\n",
    "        return self.model\n",
    "    \n",
    "    def input_block(self,inp,kernel_resize=2,pad='same'):\n",
    "        # CONV2D + BN + activation \n",
    "        x = layers.Conv2D(self.n_filters, self.kernel, padding=pad)(inp)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        if not kernel_resize:\n",
    "            return x\n",
    "        \n",
    "        # CONV2D (resize) + BN + activation\n",
    "        new_kernel = tuple(map(lambda x: x+kernel_resize,self.kernel))\n",
    "        x1 = layers.Conv2D(self.n_filters, new_kernel, padding=pad)(inp)\n",
    "        x1 = layers.BatchNormalization()(x1)\n",
    "        x1 = self.activation(x1)\n",
    "        x = layers.add([x, x1])\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def output_policy_block(self,x):\n",
    "        policy_head = layers.Conv2D(1, 1, padding='same', use_bias=False, kernel_regularizer=self.l2_reg)(x)\n",
    "        policy_head = self.activation(policy_head)\n",
    "        policy_head = layers.BatchNormalization()(policy_head)\n",
    "        policy_head = layers.Flatten()(policy_head)\n",
    "        policy_head = layers.Activation('softmax', name='policy')(policy_head)\n",
    "        return policy_head\n",
    "        \n",
    "    def output_value_block(self,x):\n",
    "        value_head = layers.GlobalAveragePooling2D()(x)\n",
    "        value_head = layers.Dense(self.n_filters, kernel_regularizer=self.l2_reg)(value_head)\n",
    "        value_head = self.activation(value_head)\n",
    "        value_head = layers.BatchNormalization()(value_head)\n",
    "        value_head = layers.Dropout(self.dropout)(value_head)\n",
    "        value_head = layers.Dense(1, activation='sigmoid', name='value', kernel_regularizer=self.l2_reg)(value_head)\n",
    "        return value_head\n",
    "    \n",
    "    def sub_residual_block(self,x,ratio=4):\n",
    "        x1 = layers.Dropout(self.dropout)(x)\n",
    "        x1 = layers.GlobalAveragePooling2D()(x1)\n",
    "        x1 = layers.Dense(self.n_filters//ratio, activation='relu')(x1)\n",
    "        x1 = layers.Dense(self.n_filters, activation='sigmoid')(x1)\n",
    "        return layers.Multiply()([x, x1])\n",
    "\n",
    "    def residual_block(self,x,pad='same'):\n",
    "        x1 = layers.Conv2D(self.n_filters, self.kernel, padding=pad)(x)\n",
    "        x1 = layers.BatchNormalization()(x1)\n",
    "        x1 = self.activation(x1)\n",
    "\n",
    "        x1 = layers.Conv2D(self.n_filters, self.kernel, padding=pad)(x1)\n",
    "        x1 = layers.BatchNormalization()(x1)\n",
    "\n",
    "        x1 = self.se_block(x1)\n",
    "\n",
    "        x = layers.add([x1, x])\n",
    "        x = self.activation(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    def activation(self,x):\n",
    "        return nn.leaky_relu(x,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regularizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/94/0fy2pb8s5jj38qy20hyt2r0m0000gn/T/ipykernel_18148/732434477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdgm_v0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDGM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdgm_v0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/94/0fy2pb8s5jj38qy20hyt2r0m0000gn/T/ipykernel_18148/3140536163.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version, dim, n_moves, n_planes, n_filters, kernel_size, l2_reg, dropout, n_res_blocks)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_filters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_res_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_res_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regularizers' is not defined"
     ]
    }
   ],
   "source": [
    "dgm_v0 = DGM() \n",
    "dgm_v0.plot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
